{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time\n",
    "from collections import deque\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "COMMONS_API = \"https://commons.wikimedia.org/w/api.php\"\n",
    "\n",
    "BEAR_SPECIES_CATEGORIES: Dict[str, str] = {\n",
    "    \"polar\": \"Category:Ursus maritimus\",\n",
    "    \"brown\": \"Category:Ursus arctos\",\n",
    "    \"american_black\": \"Category:Ursus americanus\",\n",
    "    \"asiatic_black\": \"Category:Ursus thibetanus\",\n",
    "    \"sun\": \"Category:Helarctos malayanus\",\n",
    "    \"sloth\": \"Category:Melursus ursinus\",\n",
    "    \"spectacled\": \"Category:Tremarctos ornatus\",\n",
    "    \"giant_panda\": \"Category:Ailuropoda melanoleuca\",\n",
    "    \"teddy_bear\": \"Category:Teddy_bears\",\n",
    "\n",
    "}\n",
    "\n",
    "IMAGE_EXTS = (\".jpg\", \".jpeg\", \".png\", \".webp\")\n",
    "\n",
    "\n",
    "def _session_with_retries(total_retries: int = 5) -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    adapter = requests.adapters.HTTPAdapter(max_retries=total_retries)\n",
    "    s.mount(\"https://\", adapter)\n",
    "    s.mount(\"http://\", adapter)\n",
    "    s.headers.update({\"User-Agent\": \"bear-thumb-downloader/1.1 (educational)\"})\n",
    "    return s\n",
    "\n",
    "\n",
    "def _commons_query(session: requests.Session, params: dict) -> dict:\n",
    "    r = session.get(COMMONS_API, params={**params, \"format\": \"json\"}, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def _safe_filename(title: str) -> str:\n",
    "    name = title.split(\":\", 1)[-1]\n",
    "    name = re.sub(r\"[^\\w\\-. ]+\", \"_\", name).strip().replace(\" \", \"_\")\n",
    "    return name\n",
    "\n",
    "\n",
    "def _category_members(\n",
    "    session: requests.Session,\n",
    "    category: str,\n",
    "    cmtype: str,\n",
    "    limit: int = 200,\n",
    "    cmcontinue: Optional[str] = None,\n",
    ") -> Tuple[List[str], Optional[str]]:\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"categorymembers\",\n",
    "        \"cmtitle\": category,\n",
    "        \"cmtype\": cmtype,      # \"file\" or \"subcat\"\n",
    "        \"cmlimit\": limit,\n",
    "    }\n",
    "    if cmcontinue:\n",
    "        params[\"cmcontinue\"] = cmcontinue\n",
    "\n",
    "    data = _commons_query(session, params)\n",
    "    members = data.get(\"query\", {}).get(\"categorymembers\", [])\n",
    "    titles = [m.get(\"title\", \"\") for m in members if m.get(\"title\")]\n",
    "    nxt = data.get(\"continue\", {}).get(\"cmcontinue\")\n",
    "    return titles, nxt\n",
    "\n",
    "\n",
    "def collect_files_recursive(\n",
    "    session: requests.Session,\n",
    "    root_category: str,\n",
    "    max_files: int = 200,\n",
    "    max_categories: int = 200,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Breadth-first walk subcategories and collect file titles.\n",
    "    Stops when max_files is reached.\n",
    "    \"\"\"\n",
    "    seen_cats = set([root_category])\n",
    "    q = deque([root_category])\n",
    "    file_titles: List[str] = []\n",
    "\n",
    "    while q and len(file_titles) < max_files and len(seen_cats) <= max_categories:\n",
    "        cat = q.popleft()\n",
    "\n",
    "        # 1) Collect files in this category (may be 0 for top-level taxonomy cats)\n",
    "        cmcontinue = None\n",
    "        while len(file_titles) < max_files:\n",
    "            files, cmcontinue = _category_members(session, cat, cmtype=\"file\", cmcontinue=cmcontinue)\n",
    "            for t in files:\n",
    "                tl = t.lower()\n",
    "                if any(tl.endswith(ext) for ext in IMAGE_EXTS):\n",
    "                    file_titles.append(t)\n",
    "                    if len(file_titles) >= max_files:\n",
    "                        break\n",
    "            if not cmcontinue:\n",
    "                break\n",
    "            time.sleep(0.15)\n",
    "\n",
    "        # 2) Enqueue subcategories\n",
    "        cmcontinue = None\n",
    "        while len(seen_cats) <= max_categories:\n",
    "            subs, cmcontinue = _category_members(session, cat, cmtype=\"subcat\", cmcontinue=cmcontinue)\n",
    "            for subcat in subs:\n",
    "                if subcat not in seen_cats:\n",
    "                    seen_cats.add(subcat)\n",
    "                    q.append(subcat)\n",
    "            if not cmcontinue:\n",
    "                break\n",
    "            time.sleep(0.15)\n",
    "\n",
    "    return file_titles[:max_files]\n",
    "\n",
    "def get_thumbnail_urls(session, titles, thumb_width=224):\n",
    "    out = []\n",
    "    batch_size = 50\n",
    "\n",
    "    for i in range(0, len(titles), batch_size):\n",
    "        batch = titles[i:i+batch_size]\n",
    "\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"prop\": \"imageinfo\",\n",
    "            \"titles\": \"|\".join(batch),\n",
    "            \"iiprop\": \"url\",          # <-- KEY CHANGE\n",
    "            \"iiurlwidth\": thumb_width # <-- request thumbnail width\n",
    "        }\n",
    "\n",
    "        data = _commons_query(session, params)\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "\n",
    "        for page in pages.values():\n",
    "            title = page.get(\"title\")\n",
    "            ii = page.get(\"imageinfo\", [])\n",
    "            if not title or not ii:\n",
    "                continue\n",
    "\n",
    "            info = ii[0]\n",
    "            # When iiurlwidth is set, MediaWiki commonly returns thumburl/thumbwidth\n",
    "            url = info.get(\"thumburl\") or info.get(\"url\")\n",
    "            if url:\n",
    "                out.append((title, url))\n",
    "\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def download_urls(\n",
    "    session: requests.Session,\n",
    "    pairs: List[Tuple[str, str]],\n",
    "    out_dir: str,\n",
    "    max_images: int = 30,\n",
    ") -> List[str]:\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    saved: List[str] = []\n",
    "\n",
    "    for title, url in tqdm(pairs[:max_images], desc=f\"Downloading → {out_dir}\"):\n",
    "        try:\n",
    "            resp = session.get(url, timeout=30)\n",
    "            resp.raise_for_status()\n",
    "\n",
    "            path = os.path.join(out_dir, _safe_filename(title))\n",
    "            with open(path, \"wb\") as f:\n",
    "                f.write(resp.content)\n",
    "\n",
    "            saved.append(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Skip: {title} ({e})\")\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    return saved\n",
    "\n",
    "\n",
    "def download_bears(\n",
    "    species_key: str,\n",
    "    out_root: str = \"bear_images_small\",\n",
    "    max_images: int = 30,\n",
    "    thumb_width: int = 224,\n",
    ") -> List[str]:\n",
    "    if species_key not in BEAR_SPECIES_CATEGORIES:\n",
    "        raise ValueError(f\"Unknown species_key={species_key}. Choose one of: {sorted(BEAR_SPECIES_CATEGORIES)}\")\n",
    "\n",
    "    session = _session_with_retries()\n",
    "    root_cat = BEAR_SPECIES_CATEGORIES[species_key]\n",
    "\n",
    "    # Collect file titles recursively because top-level taxonomy categories can be mostly subcats\n",
    "    titles = collect_files_recursive(session, root_cat, max_files=max_images * 5)\n",
    "\n",
    "    if not titles:\n",
    "        print(f\"No files found under {root_cat}. Try increasing max_categories or using a more specific subcategory.\")\n",
    "        return []\n",
    "\n",
    "    pairs = get_thumbnail_urls(session, titles, thumb_width=thumb_width)\n",
    "    out_dir = os.path.join(out_root, species_key)\n",
    "\n",
    "    return download_urls(session, pairs, out_dir, max_images=max_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50143c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading → bear_images_small/brown: 100%|██████████| 20/20 [02:06<00:00,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "paths = download_bears(\"brown\", max_images=20, thumb_width=224)\n",
    "print(\"Saved:\", len(paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dc420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading → bear_images_small/polar: 100%|██████████| 20/20 [02:04<00:00,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example:\n",
    "paths = download_bears(\"polar\", max_images=20, thumb_width=224)\n",
    "print(\"Saved:\", len(paths))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
